---
title: "Reproducibility: you can do data analysis without it, but should you?"  
author: 
  - "Tiffany Timbers (UBC)"
  - "`r Sys.Date()`"
date: 'bit.ly/SES_Workshop_2022'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: '%current%'
      titleSlideClass: [top, left]
      ratio: '16:9'

---

class: middle

## What is **reproducibility**?

#### Reaching the same result given the same input, computational methods, and conditions<sup>1</sup>

<br>

*Where:*

input = data

computational methods = computer code

conditions = computational environment (e.g., programming language & itâ€™s dependencies)

.footnote[
[1] Committee on Reproducibility and Replicability in Science (2019), Reproducibility and Replicability in Science, Washington, D.C.: National Academies Press. https://doi.org/10.17226/25303
]

---

This is distinct from **replicability**, 
which obtaining consistent results across studies 
aimed at answering the same scientific question, 
each of which has obtained its own data.<sup>1</sup>

.footnote[
[1] Committee on Reproducibility and Replicability in Science (2019), Reproducibility and Replicability in Science, Washington, D.C.: National Academies Press. https://doi.org/10.17226/25303
]

---

## How does this fit in with a "Theory and Methods for Building Successful Data Analyses"?

Reproducible data analysis can "help" make an analysis successful by helping build "trust" in the analysis.
This trust is important for stakeholders, of whom the application of the analysis impacts.

For example, it can:

1. provide evidence that the results or product could be regenerated given the same input computational methods, and conditions

2. is transparent - a human can audit all steps taken during analysis

3. if also version controlled, there is also a complete record of how and why analysis decisions were made

---

## Reproducibility failures as reported by Data Scientists

We asked graduate and undergraduate Data Scientists (in training) 
for real life stories of data analysis workflow challenges and failures 
they had faced in the past (either at school or on the job).

From the 76 stories we collected, 
four main themes related to failures in reproducibility emerged:

1. documentation

2. code

3. version control

4. environments

---

## Impacts of reproducibility failures as reported by Data Scientists

These 76 stories also described the impacts 
as well as the reproducibility failures,
and they included:

1. loss of time (time)

2. loss of reputation (reputation)

3. increased costs of hiring someone else to redo the work (cost)

4. work being discarded due to lack of trustworthiness (work discarded)

---

## Levels that non-reproducible analysis can have an impact on 

- Data Scientist
- Organization
- Beyond (e.g., Society)

---

## Potential impacts on the Data Scientist

---

## Potential impacts on the Organization

---

## Potential impacts beyond

1. Case 1

2. Case 2

3. Case 3

---

## Case 1

---

## Case 2


---

## Case 3


---

## Impact levels revisited


---

## Summary


---

## Acknowledgements


---


class: inverse, center, middle

# Questions?



### Tiffany Timbers

#### talk slides: *[https://bit.ly/TBD](https://bit.ly/TBD)*
